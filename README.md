## Проект "Поисковая система".

Содержит две программы:<br>
**SpiderApp.exe** - программа-скрэйпер.<br> 
Получает файл с настройками подключения к БД, исходной страницей, глубиной максимального погружения.<br> 
Получает данные по ссылке, извлекает текст, подсчитывает повторение слов на странице, записывает эти данные в БД.<br> 
Ищет новые ссылки на странице, запускает сбор данных с каждой найденой страницы, если максимальная глубина погружения не достигнута.

**HttpServerApp.exe** - программа-http-сервер с поисковой строкой.<br>
Запускает локальный сервер с доступом к БД.<br> 
На странице localhost отображает поисковую строку.<br> 
Пользователь вводит поисковый запрос, программа обращается к БД и возвращает до 10 ссылок с максимальным количеством повторений слов из поискового запроса.

**Предполагаемое использование:**
1. Заполнение файла config.ini.
2. Сборка проекта.
3. Запуск SpiderApp.exe - происходит заполнение БД.
4. Запуск HttpServerApp.exe - запуск интерфейса с поисковой строкой. На запрос возвращается список ссылок.
5. Повторный запуск SpiderApp.exe с тем же стартовым URL приводит к повторной обработке страниц и обновлению индексированных данных в БД.

**Описание модулей:**
1. spider - программа - паук. Предназначена для считывания данных со страниц по URL, поиска новых URL, отбора слов на странице, подсчета количества повторений, записи индексированных данных в БД.

    1.1. main() - исполняемая часть программы spider. Инициирует считывание файла настроек, инициирует клиент БД, запускает parseLink() для исходного URL из файла настроек.

        Функции
            void threadPoolWorker() - обработчик очереди задач.
            void parseLink() - обработчик данных по ссылке.
        Аргументы:
            экземпляр Link - ссылка на страницу.
            экземпляр Client - клиент БД (подключение к базе данных).
            depth - остаток запаса глубины перехода по ссылке.
            вектор scrapped - перечень URL, которые уже были переданы в обработку.
        Логика:
            parseLink() пытается получить содержимое страницы по ссылке. Если содержимое получено, извлекает текст, запускает индексацию текста, запускает запись индексированных данных в БД. Далее, если depth не достигла 0, запускает поиск URL в содержимом страницы. Для каждго URL, которого еще нет в векторе scrapped, запускает новую задачу на выполнение parseLink() с новым экземпляром Link и счетчиком глубины = depth - 1.

    1.2. db_client - клиент БД. Предназначен для подключения к БД, запросов к БД, записи данных в БД в процессе работы spider.

        Client - класс-наследник класса Database (п.3 database). Содержит подготовленные SQL-запросы для записи, поиска, удаления данных БД.

        Методы:
            int findDoc(url) - возвращает ID - ключ, соответствующий url в таблице docs. Если url нет в БД, возвращает 0.

            int findWord(word) - возвращает ID - ключ, соответствующий word в таблице words. Если слова нет в БД, возвращает 0.

            void fillDatabase() - отвечает за запись данных в БД:

                                - ищет в БД URL - соответствующий экземмпляр Link. Если находит, удаляет существующие записи по количеству слов по этому URL (позволяет обновлять индексы при перезапуске программы spider).

                                - если URL найдена, возвращает ID, иначе создает новую запись с новым ID, если данные по количеству слов не пустые.

                                - записывает в БД связку ID страницы | ID слова | кол-во слов.

                                - если слова еще нет в БД, предварительно создает слово в БД.

        std::mutex_ - защищает перезапись данных в БД от одновременных потоков.


    1.3. http_utils - модуль функций, отвечающих за извлечение данных со страницы по ссылке и работу с URL в тексте.

            Link prepareLink(url) - преобразует текст URL в формате строки в экземпляр Link.
            std::vector<Link> assembleLinks() - собирает в вектор все URL из текста.
            std::string stringulateLink() - преобразует экземпляр Link в строку URL.

    1.4. link - структура, экземпляры которой содержат данные о протоколе подключения, имени хоста и запросе к хосту.

    1.5. text_processing - модуль функций, отвечающих за обработку текста со страницы.

            std::string cleanRegex() - получает строку, заменяет все, кроме букв, на " ", возвращает результат.

            std::string lowerCase() - получает строку, переводит буквы в нижний регистр, возвращает результат.

            std::unordered_map<std::string, int> indexer() - подсчитывает количество повторений слов в тексте, игнорирует слова короче 3 или длиннее 32 букв. Возвращает контейнер <слово, количество повторений>.

            std::string cleanTags() - получает строку, удаляет все символы, заключенные в <> - удаление html тэгов, возвращает результат.

2. config - модуль, обрабатывающий исходные настройки программы.

    2.1. Config.ini - файл с настройками. 

            Содержит строки в виде "параметр"="значение параметра"
            db_host - хост базы данных.
            db_port - порт базы данных.
            db_name - имя БД.
            db_user - имя пользователя БД.
            db_password - пароль для подключения к БД.
            start_url - стартовая страница для начала работы программы spider.
            crawl_depth - максимальная глубина.
            port - порт запуска сервера с поисковой строкой.

    2.2. Config - класс Config. 
    
            Конструктор с параметрами принимает адресс файла сonfig.ini, считывает данные, записывает содержимое в контейнер <параметр, значение параметра>.

            Методы:
            std::string getConfig() - возвращает значение параметра по ключу.

3. database - модуль, отвечающий за взаимодействие программы с БД.

    3.1. Database - класс подключения к БД. 
    
            Конструктор в качестве параметра получает экземпляр Config, из которого получает параметры подключения к БД, запускает создание структуры данных в БД:

                | id слова | слово | -- справочник слов.

                | id url | url | -- справочник страниц.

                | id | id слова | id url | кол-во повторений слов | -- статистика по повторению слов на странице.

4. http_server - программа - веб-интерфейс. Содержит поисковую строку для ввода запроса. Выводит в браузер ответ - результат обработки запроса.

    4.1. main() - исполняемая часть программы http_server:

        - создает Config.
        - запускает локальный сервер с поисковой строкой.
        - выводит в консоль сообщение с адресом сервера.
        - void httpServer() - запуск http-сервера.

    4.2. http_connection - модуль функций работы http-сервера. 
    
        В исходный код - в HttpConnection::HttpConnection - добавлен параметр search - поисковый движок.

    4.3. search_engine - библиотека отвечающая за запросы поисковой строки к БД.

        Search - класс-наследник Database.

        Методы:
            std::vector<std::string> searchEngine(): 

            - получает поисковый запрос.

            - вызывает функции обработки текста (нижний регистр, очистка от не-букв, индексирование).

            - формирует вектор - уникальные слова в поисковом запросе.

            - формирует SQL-запрос с динамическими параметрами, ищет совпадения через WHERE word IN (список слов). 

            - возвращает 10 страниц с максимальной суммой повторений слов из запроса.